{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nimport math\nimport matplotlib.pyplot as plt\nimport torchvision\nimport torchvision.transforms as transforms\n\n\n\ntorch.manual_seed(111)\n\n\n\ndevice = \"\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"gpu available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"gpu not aviailable\")\n    \n    \n    \ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n)\n\n\n\n\n\ntrain_set = torchvision.datasets.MNIST(\n    root=\".\", train=True, download=True, transform=transform\n)\n\n\n\n\nbatch_size = 32\ntrain_loader = torch.utils.data.DataLoader(\n    train_set, batch_size=batch_size, shuffle=True\n)\n\n\n\nreal_samples, mnist_labels = next(iter(train_loader))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n    plt.xticks([])\n    plt.yticks([])\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:18:16.092163Z","iopub.execute_input":"2024-03-29T14:18:16.093121Z","iopub.status.idle":"2024-03-29T14:18:25.240621Z","shell.execute_reply.started":"2024-03-29T14:18:16.093055Z","shell.execute_reply":"2024-03-29T14:18:25.239573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(784, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        x = x.view(x.size(0), 784)\n        output = self.model(x)\n        return output\n\n    \n\ndiscriminator = Discriminator().to(device=device)\n\n\n\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(100, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 784),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        output = self.model(x)\n        output = output.view(x.size(0), 1, 28, 28)\n        return output\n\ngenerator = Generator().to(device=device)\n\n\n\n\nlr = 0.0001\nnum_epochs = 50\nloss_function = nn.BCELoss()\n\noptimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\noptimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n\n\n\n\nfor epoch in range(num_epochs):\n    for n, (real_samples, mnist_labels) in enumerate(train_loader):\n        # Data for training the discriminator\n        real_samples = real_samples.to(device=device)\n        real_samples_labels = torch.ones((batch_size, 1)).to(\n            device=device\n        )\n        latent_space_samples = torch.randn((batch_size, 100)).to(\n            device=device\n        )\n        generated_samples = generator(latent_space_samples)\n        generated_samples_labels = torch.zeros((batch_size, 1)).to(\n            device=device\n        )\n        all_samples = torch.cat((real_samples, generated_samples))\n        all_samples_labels = torch.cat(\n            (real_samples_labels, generated_samples_labels)\n        )\n\n        # Training the discriminator\n        discriminator.zero_grad()\n        output_discriminator = discriminator(all_samples)\n        loss_discriminator = loss_function(\n            output_discriminator, all_samples_labels\n        )\n        loss_discriminator.backward()\n        optimizer_discriminator.step()\n\n        # Data for training the generator\n        latent_space_samples = torch.randn((batch_size, 100)).to(\n            device=device\n        )\n\n        # Training the generator\n        generator.zero_grad()\n        generated_samples = generator(latent_space_samples)\n        output_discriminator_generated = discriminator(generated_samples)\n        loss_generator = loss_function(\n            output_discriminator_generated, real_samples_labels\n        )\n        loss_generator.backward()\n        optimizer_generator.step()\n\n        # Show loss\n        if n == batch_size - 1:\n            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:41:17.791116Z","iopub.execute_input":"2024-03-29T12:41:17.79153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_space_samples = torch.randn(batch_size, 100).to(device=device)\ngenerated_samples = generator(latent_space_samples)\n\n\n\ngenerated_samples = generated_samples.cpu().detach()\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n    plt.xticks([])\n    plt.yticks([])\n    \n    \n    \n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:28:54.929422Z","iopub.execute_input":"2024-03-30T07:28:54.930114Z","iopub.status.idle":"2024-03-30T07:28:55.256631Z","shell.execute_reply.started":"2024-03-30T07:28:54.930088Z","shell.execute_reply":"2024-03-30T07:28:55.255476Z"},"trusted":true},"execution_count":null,"outputs":[]}]}